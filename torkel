#! /usr/bin/env python

import os
import sys
import os

import itertools
import argparse
import errno
import math

import pickle
import gffutils

# from collections import deque


from modules import create_splice_graph as splice_graph
from modules import mummer_wrapper 
from modules import graph_chainer 

def pickle_dump(data, filename):
    with open(os.path.join(args.outfolder,filename), 'wb') as f:
        # Pickle the 'data' dictionary using the highest protocol available.
        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)


def pickle_load(filename):
    with open(filename, 'rb') as f:
        # The protocol version used is detected automatically, so we do not
        # have to specify it.
        data = pickle.load(f)
    return data


def construct_graph(args):
    fn = gffutils.example_filename(args.gff)
    db = gffutils.create_db(fn, dbfn='test.db', force=True, keep_order=True, merge_strategy='merge', sort_attribute_values=True)
    db = gffutils.FeatureDB('test.db', keep_order=True)

    gene_graphs, collapsed_exon_to_transcript = splice_graph.create_graph(db)

    topological_sorts = splice_graph.create_global_source_sink(gene_graphs)    
    paths = splice_graph.derive_path_cover(gene_graphs, topological_sorts)
    
    refs_sequences = splice_graph.get_sequences_from_choordinates(gene_graphs, args.ref)
    # print(refs_sequences)
    # dump to pickle here! Both graph and reference seqs
    pickle_dump(gene_graphs, 'graphs.pickle')
    pickle_dump(topological_sorts, 'top_sorts.pickle')
    pickle_dump(refs_sequences, 'refs_sequences.pickle')
    pickle_dump(paths, 'paths.pickle')
    pickle_dump(collapsed_exon_to_transcript, 'collapsed_exon_to_transcript.pickle')


def align_reads(args):
    gene_graphs = pickle_load( os.path.join(args.outfolder, 'graphs.pickle') )
    topological_sorts = pickle_load( os.path.join(args.outfolder, 'top_sorts.pickle') )
    refs_sequences = pickle_load( os.path.join(args.outfolder, 'refs_sequences.pickle') )
    path_covers = pickle_load( os.path.join(args.outfolder, 'paths.pickle') )
    collapsed_exon_to_transcript = pickle_load( os.path.join(args.outfolder, 'collapsed_exon_to_transcript.pickle') )

    mummer_wrapper.find_mems(refs_sequences, args.reads, args.outfolder)
    mems  = mummer_wrapper.parse_results(args.outfolder)

    for gene_id in gene_graphs:
        gene_graph = gene_graphs[gene_id]
        topological_sort = topological_sorts[gene_id]
        path_cover = path_covers[gene_id]
        graph_chainer.calc_last2reach(gene_graph, path_cover, topological_sort)
        sys.exit()
    # non_redundant_segments = splice_graph.collapse_identical_for_mumer(exon_db)

    # exon_db = parse_tsv()
    # graph = create_graph()
    # graph_top_sorted_order = top_sort_graph()
    # hits = run_mummer(non_redundant_segments, reads )
    # for read_hits in hits:
    #     chain_hits_read()



if __name__ == '__main__':

    parser = argparse.ArgumentParser(description="torkel -- Classify long reads based on transcript graphs")
    subparsers = parser.add_subparsers(help='Subcommands for eaither constructing a graph, or align reads')
    # parser.add_argument("-v", help='Different subcommands for eaither constructing a graph, or align reads')

    pipeline_parser = subparsers.add_parser('pipeline', help= "Construct a splicing graph and align reads to it")
    construct_graph_parser = subparsers.add_parser('construct', help= "Construct a splicing graph")
    align_reads_parser = subparsers.add_parser('align', help="Classify and align reads with colinear chaining to DAGs")

    pipeline_parser.add_argument('gff', type=str, help='Path to gff or gtf file with gene models.')
    pipeline_parser.add_argument('ref', type=str, help='Reference genome (fasta)')
    pipeline_parser.add_argument('reads', type=str, help='Path to fasta/fastq file with reads.')
    pipeline_parser.add_argument('outfolder', type=str, help='Path to fasta file with a nucleotide sequence (e.g., gene locus) to simulate isoforms from.')
    # pipeline_parser.add_argument('--pickle', action='store_true', help='Store the graph on file.')
    pipeline_parser.set_defaults(which='pipeline')


    construct_graph_parser.add_argument('gff', type=str, help='Path to gff or gtf file with gene models.')
    construct_graph_parser.add_argument('ref', type=str, help='Reference genome (fasta)')
    construct_graph_parser.add_argument('outfolder', type=str, help='Path to fasta file with a nucleotide sequence (e.g., gene locus) to simulate isoforms from.')
    # construct_graph_parser.add_argument('--pickle', action='store_true', help='Store the graph on file.')
    construct_graph_parser.set_defaults(which='construct_graph')


    align_reads_parser.add_argument('refs', type=str, help='Path to fasta file with a nucleotide sequence (e.g., gene locus) to simulate isoforms from.')    
    align_reads_parser.add_argument('reads', type=str, help='Path to fasta file with a nucleotide sequence (e.g., gene locus) to simulate isoforms from.')
    align_reads_parser.add_argument('outfolder', type=str, help='Path to fasta file with a nucleotide sequence (e.g., gene locus) to simulate isoforms from.')    

    align_reads_parser.set_defaults(which='align_reads')

    args = parser.parse_args()


    if len(sys.argv)==1:
        parser.print_help()
        sys.exit()

    if args.which == 'construct_graph':
        construct_graph(args)
    elif args.which == 'align_reads':
        align_reads(args)
    elif args.which == 'pipeline':
        construct_graph(args)
        align_reads(args)        
    else:
        print('invalid call')
